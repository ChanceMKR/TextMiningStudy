{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading model.safetensors: 100%|██████████| 268M/268M [00:30<00:00, 8.86MB/s]\n",
      "2023-08-10 20:14:22.333796: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 20:14:22.372716: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 279kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 643kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성분석 결과: POSITIVE, 감성스코어: 0.9999\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\"sentiment-analysis\")\n",
    "result = clf(\"what a beautiful day!\")[0]\n",
    "print(f\"감성분석 결과: {result['label']}, 감성스코어: {result['score']:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 1.42MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 548M/548M [01:18<00:00, 7.00MB/s]\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.44MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 840kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 5.16MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/chance/opt/anaconda3/envs/tf/lib/python3.10/site-packages/transformers/generation/tf_utils.py:854: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, but I knew that I could find her anywhere on the outside. In the shadows—afterwards—it was difficult finding her.\"\n",
      "\n",
      "A few days later, when\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")\n",
    "result = text_generator(\"Alice was beginning to get very tired of sitting by her sister on the bank,\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6 자동 클래스를 이용한 토크나이저와 모형의 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chance/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 103kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 433/433 [00:00<00:00, 3.67MB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 603kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 817kB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Auto Classes를 이용해 사전학습된 내용에 맞는 토크나이저와 모형을 자동으로 설정\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbert-base-cased-finetuned-mrpc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbert-base-cased-finetuned-mrpc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 의미적으로 유사한 두 문장을 선언\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chance/Desktop/Coding/TextMining/textmining14.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m input_sentence \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mShe angered me with her inappropriate comments, rumor-spreading, and disrespectfulness at the formal dinner table\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/transformers/utils/import_utils.py:1026\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1025\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1026\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/transformers/utils/import_utils.py:1005\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1005\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[39m.\u001b[39mformat(name))\n\u001b[1;32m   1007\u001b[0m \u001b[39m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m backends \u001b[39mand\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "# Auto Classes를 이용해 사전학습된 내용에 맞는 토크나이저와 모형을 자동으로 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-cased-finetuned-mrpc\"\n",
    ")\n",
    "\n",
    "# 의미적으로 유사한 두 문장을 선언\n",
    "input_sentence = \"She angered me with her inappropriate comments, rumor-spreading, and disrespectfulness at the formal dinner table\"\n",
    "target_sequence = \"she made me angry when she was rude at dinner\"\n",
    "# 토큰화\n",
    "tokens = tokenizer(input_sentence, target_sequence, return_tensors=\"pt\")\n",
    "\n",
    "# 모형으로 결과를 예측\n",
    "logits = model(**tokens).logits\n",
    "\n",
    "# 소프트맥스를 이용해 결과값을 클래스에 대한 확률로 변환\n",
    "results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "\n",
    "for i, label in enumerate(['no', 'yes']):\n",
    "    print(f\"{label}: {int(round(results[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f47abbb47edac558f216fc00357fedb75d7e5a9ed182f04a5060563e48fc6d82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
