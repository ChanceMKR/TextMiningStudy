{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['역시', '헐', '##리', '##우', '##드', '스', '##케', '##일', '##이', '너', '##무', '##커', '##서', '각', '캐', '##릭', '##터', '알', '##고', '##봐', '##야', '할', '##거', '##같', '##음']\n",
      "['▁역시', '▁', '헐', '리', '우', '드', '▁', '스케', '일', '이', '▁너무', '커', '서', '▁각', '▁캐릭터', '▁알고', '봐야', '▁할', '거', '같', '음']\n",
      "--------------------------------------------------------\n",
      "['블', '##랙', '##팬', '##서', '[UNK]', '나', '##쁜', '##놈', '##이', '##네', '##요', '전', '##세', '##계', '##의', '초', '##능', '##력', '##과', '기', '##술', '##력', '우', '##주의', '능', '##력', '##자', '##들이', '쳐', '##들어', '##와', '싸', '##우', '##는데', '칼', '도', '##끼', '##들', '##고', '있는', '부', '##족', '##놈', '##들은', '뭐', '##야', '.', '.', '.', '.', '.', '노', '##예', '##라', '##서', '첨', '##단', '##무', '##기', '안', '##주는', '##겨', '?', '블', '##랙', '##팬', '##서', '##란', '캐', '##릭', '##터', '자', '##체가', '영화', '##에', '민', '##폐', '##같', '##다', '.', '.', '.', '.', '그', '##냥', '죽', '##여', '##서', '없', '##애', '##라']\n",
      "['▁블랙', '팬', '서', '▁드', '릅', '게', '▁나쁜', '놈', '이', '네요', '▁전세계', '의', '▁초', '능력', '과', '▁기술', '력', '▁우주', '의', '▁능력', '자들이', '▁', '쳐', '들어', '와', '▁싸', '우', '는데', '▁칼', '▁', '도', '끼', '들', '고', '▁있는', '▁부족', '놈', '들은', '▁뭐', '야', '.', '.', '...', '노', '예', '라', '서', '▁첨단', '무', '기', '▁안', '주는', '겨', '?', '▁블랙', '팬', '서', '란', '▁캐릭터', '▁자체가', '▁영화', '에', '▁민', '폐', '같', '다', '...', '.', '그', '냥', '▁죽', '여', '서', '▁없애', '라']\n",
      "--------------------------------------------------------\n",
      "['후', '##속', '##편', '##을', '위한', '영화', '##일', '##뿐', '.', '설', '##명', '##도', '액', '##션', '##도', '지', '##겨', '##웠다', '.', '블', '##랙', '##팬', '##서', '##도', '졸', '##리', '##더', '##니', '요', '##새', '어', '##벤', '##져', '##스는', '관', '##객', '##은', '안', '##중에', '##도', '없다', '.', '아', '##무', '##튼', '설', '##명', '##지', '##루', '##하고', '액', '##션', '##도', '시', '##시', '##하고', '보다', '##보다', '졸', '##기', '##까지', '이', '##걸', '##돈', '##내', '##고', '##보', '##라', '##니', '.', '넘', '##하', '##네']\n",
      "['▁후속', '편', '을', '▁위한', '▁영화', '일', '뿐', '.', '▁설명', '도', '▁액션', '도', '▁지', '겨', '웠다', '.', '블랙', '팬', '서', '도', '▁', '졸', '리', '더니', '▁요', '새', '▁어', '벤', '져', '스는', '▁관객', '은', '▁안', '중', '에도', '▁없다', '.', '▁아무', '튼', '▁설명', '지', '루', '하고', '▁액션', '도', '▁시', '시', '하고', '▁보다', '보다', '▁', '졸', '기', '까지', '▁이', '걸', '돈', '내', '고', '보', '라', '니', '.', '▁넘', '하', '네']\n",
      "--------------------------------------------------------\n",
      "['[UNK]']\n",
      "['▁', 'ᄑ', 'ᄒ', 'ᄒ', 'ᄒ']\n",
      "--------------------------------------------------------\n",
      "['1800', '##년대', '초', '##에', '인구', '##보다', '6', '##배', '##가', '증', '##가', '##하고', '자', '##원', '이', '##용', '##율', '##은', '70', '##배', '##가', '증', '##가', '##한', '현재의', '지', '##구', '.', '.', '.', '인', '##간의', '탐', '##욕', '##과', '인구', '##수', '증', '##가는', '지', '##구', '##온', '##난', '##화', '##와', '자', '##원', '고', '##갈', '##이', '##라는', '대', '격', '##변', '##을', '겪', '##게', '될', '것이다', '.', '이', '##게', '먼', '미', '##래', '##가', '될', '##지', '아', '##니', '##면', '천', '##지', '창', '##조', '##주의', '종', '##말', '##이', '될', '##지', '.', '.', '모', '##르', '##지만', ',', '타', '##이', '##탄', '행', '##성', '##처럼', '인', '##류', '반', '##을', '죽', '##일', '수', '있는', '우', '##울', '##한', '미', '##래', '##가', '오', '##지', '않는다', '##고', '누', '##가', '장', '##담', '##할', '##까', '?', '그', '##런', '종', '##말', '##적', '세계', '##관', '##을', '마', '##블', '##의', '히', '##어로', '##들의', '총', '##집', '##합', '##으로', '[UNK]', '그', '##려', '##냈다', '.', '단', ',', '등', '##장', '히', '##어로', '##들이', '많다', '##보', '##니', '스', '##토', '##리', '초', '##반', '집', '##중', '##이', '좀', '힘', '##들', '##었다', '.']\n",
      "['▁1', '800', '년대', '▁초', '에', '▁인구', '보다', '▁6', '배', '가', '▁증가', '하고', '▁자원', '▁이용', '율은', '▁70', '배', '가', '▁증가한', '▁현재', '의', '▁지구', '...', '인', '간', '의', '▁탐', '욕', '과', '▁인구', '수', '▁증가', '는', '▁지구', '온', '난', '화', '와', '▁자원', '▁고', '갈', '이라는', '▁대', '▁격', '변', '을', '▁겪', '게', '▁될', '▁것이다', '.', '▁이', '게', '▁', '먼', '▁미래', '가', '▁될', '지', '▁아니면', '▁천', '지', '▁창조', '주의', '▁종', '말', '이', '▁될', '지', '.', '.', '모', '르', '지만', ',', '타', '이', '탄', '▁행', '성', '처럼', '▁인', '류', '▁반', '을', '▁죽', '일', '▁수', '▁있는', '▁우', '울', '한', '▁미래', '가', '▁오', '지', '▁않는다', '고', '▁누가', '▁장', '담', '할', '까', '?', '그런', '▁종', '말', '적', '▁세계', '관', '을', '▁마', '블', '의', '▁', '히', '어', '로', '들의', '▁총', '집', '합', '으로', '▁재', '밌', '게', '▁그려', '냈다', '.', '단', ',', '▁등장', '▁', '히', '어', '로', '들이', '▁많다', '보니', '▁스토리', '▁초반', '▁집중', '이', '▁좀', '▁힘들', '었다', '.']\n",
      "--------------------------------------------------------\n",
      "['별', '반', '##개', '##도', '아', '##깝', '##다', '.', '시', '##빌', '##부터', '쓰', '##레', '##기', '##더', '##니', '혹', '##시', '##나', '##하고', '[UNK]', '역시', '##나', '.', '쓰', '##레', '##기', '.', '이런', '##걸', '##보', '##고', '좋', '##아', '날', '##리', '##치는', '호', '##구', '##놈', '##들은', '뭔', '##지', '.', '다', '##운', '##싸', '##이트', '##에서', '[UNK]', '봐', '##도', '아', '##깝', '##겠', '##다', '.', '이', '##건', '##무', '##슨', '내', '##용', '##도', '##없', '##고', '.', '[UNK]', '짜', '##장이', '##랑', '비', '##벼', '##놓', '##은', '##맛', '.', '개', '##밥', '##이지']\n",
      "['▁별', '▁반', '개', '도', '▁아', '깝', '다', '.', '▁시', '빌', '부터', '▁쓰레기', '더니', '▁', '혹', '시', '나', '하고', '▁', '밨', '더니', '▁역시', '나', '.', '▁쓰레기', '.', '▁이런', '걸', '보고', '▁좋아', '▁날', '리', '치는', '▁호', '구', '놈', '들은', '▁', '뭔', '지', '.', '▁', '다운', '싸', '이', '트', '에서', '▁300', '우', 'ᅡᄂ', '에', '▁봐', '도', '▁아', '깝', '겠다', '.', '▁이', '건', '무', '슨', '▁내용', '도', '없', '고', '.', '▁', '짬', '뽕', '이', '랑', '▁짜', '장이', '랑', '▁비', '벼', '놓', '은', '맛', '.', '▁개', '밥', '이', '지']\n",
      "--------------------------------------------------------\n",
      "['최고', '##의', '빌', '##런', '##은', '빅', '##지', '##훈', '.', '진', '##짜', '오', '##역', '논', '##란', '나', '##오', '##기', '##전', '##까지', '.', '진', '##짜', '마지막', '어', '##머', '##님', '##한', '##테', '전', '##화', '##하다', '##가', '닉', '##퓨', '##릭', '죽', '##은', '##지', '알', '##았다', '.']\n",
      "['▁최고의', '▁빌', '런', '은', '▁빅', '지훈', '.', '▁진짜', '▁오', '역', '▁논란', '▁나오', '기', '전', '까지', '.', '▁진짜', '▁마지막', '▁어', '머', '님', '한테', '▁전화', '하다', '가', '▁', '닉', '퓨', '릭', '▁죽', '은', '지', '▁알', '았다', '.']\n",
      "--------------------------------------------------------\n",
      "['이', '##게', '뭔', '영화', '##인', '##지', '참', '.', '.', '.']\n",
      "['▁이', '게', '▁', '뭔', '▁영화', '인지', '▁참', '...']\n",
      "--------------------------------------------------------\n",
      "['상', '##상', '##력', '끝', '##판', '##왕', '!', '!']\n",
      "['▁상', '상', '력', '▁끝', '판', '왕', '▁', '!', '!']\n",
      "--------------------------------------------------------\n",
      "['대', '##박', '!', '각', '히', '##어로', '영화', '##는', '너', '##무', '[UNK]', '어', '##벤', '##져', '##스는', '별', '##로', '##라', '##서', '이', '##번', '##엔', '극', '##장', '##가', '##서', '안', '##봤', '##는데', '.', '.', '.', '너', '~', '무', '[UNK]', '!', '!', '!', '이', '##게', '7', '##점', '##대', '평', '##점', '##이', '##라', '##니', '.', '.']\n",
      "['▁대', '박', '!', '▁각', '▁', '히', '어', '로', '▁영화', '는', '▁너무', '▁재', '밌', '는데', '▁어', '벤', '져', '스는', '▁', '별로', '라', '서', '▁이번', '엔', '▁', '극장', '가', '서', '▁안', '봤', '는데', '...', '▁너', '~', '무', '▁재', '밌', '음', '!', '!', '!', '▁이', '게', '▁7', '점', '대', '▁평', '점', '이라', '니', '.', '.']\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer1 = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "tokenizer2 = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "data = pd.read_csv(\"./data/daum_movie_review.csv\")\n",
    "for text in data.review[100:110]:\n",
    "    print(tokenizer1.tokenize(text))\n",
    "    print(tokenizer2.tokenize(text))\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cbfa331c34500466df6bcee3d13d6f1df6471fa5443ed47e9e61f565d6a8d51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
